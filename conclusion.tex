\section{Conclusion and Future Work}\label{sec:conclusion}

Personalized recommender system will take on more and more significant role in humanbeing's life with the soaring choices as well as the people's pursuit for high efficiency and fast speed of life. Undoubtedly, the recommender system will be prefered if its focus is the specific target user rather than a group of people or the actions of similar persons. Whereas, current recommender system for clothing is mostly recommend by group identities, which neglects the personality of the users. In this paper, we propose a novel framework for personalized recommender system which can recommend by each user's preference.\\

	In our framework, there are three major process: model apparel item, model user preference, recommend by prediction ratings. We first model the apparel item as the vector which combined the textual vector and image vector together by a certain weight. The bit in textual vector will be labeled 1 if the textual labels contains the corresponding attributes (such as sports, lovely, loose, cotton, etc). Otherwise, it will be labeled 0. The image vector is the coefficients based on a dictionary learned from all the images by K-SVD algorithm. Next, the user preference will be collected through some action records of the user such as scanning time, favorite items, purchase history of some clicking records. In our framework the preference will be represented by the ratings from 1 - 5 to show different degree. The rating will be linked with the apparel items thus a map from the apparel set to the preference set is established for a specific user. Later, we can leverage SVM(Support Vector Machine) based on the existing map as training data to predict the unknown preference of the remained clothes. Finally, the framework will recommed to the user a list of clothes ranked by the predicted ratings.\\
	
	There are still some future work for our framework.
\subsection{Learn combination weight of the vector}
The combination weight of the textual label and the image is learned to best fit the different inclination of different users. Some users may inline to focus more on images while some may make more emphasis on textual labels. Therefore the combination weight is varied from person to person. We can learn this weight by test the accuracy of different weight for a specific user. Then choose the weight that can serve the best accuracy under the condition that other variables are kept constant.

\subsection{Quantify the user actions to ratings}
In the Section \ref{sec:approach} Model user preference part, we have talked about the ratings can be modeled from the user actions including scanning time, etc. Howerver, how to quantify these actions and weight these different action are still under experiment. Undoubtedly this work will realease the burden of the users to rate the clothing under consciousness. On top of that, some inconscious actions may be more accurate to relect the user's preference.

